{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LinusBach/SentimentAnalysis/blob/main/sentiAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FL2Mbm_sxwb"
   },
   "source": [
    "# Simple sentiment analysis\n",
    "\n",
    "Sentiment analysis, using iMDB database\n",
    "\n",
    "First, implement and train a feedforward NN model with TF-IDF. And then train your\n",
    "model using word2vec embedding. Report both training and development accuracy on\n",
    "the dataset. Try to use stochastic gradient descent or (mini-batch) stochastic gradient\n",
    "descent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T09:13:20.368413Z",
     "start_time": "2023-05-12T09:13:15.922079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (2.11.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.42.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (2.11.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (4.5.0)\r\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (2.11.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.3.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (16.0.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (2.11.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (2.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.24.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (66.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (3.7.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: packaging in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (23.0)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (3.19.6)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.6.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.4)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.6.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.29.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.7.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.2.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\r\n",
      "Requirement already satisfied: nltk in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: tqdm in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from nltk) (4.65.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from nltk) (2023.5.5)\r\n",
      "Requirement already satisfied: joblib in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from nltk) (1.2.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/uni/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (4.3.1)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from gensim) (1.10.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from gensim) (1.24.3)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/uni/anaconda3/envs/tf/lib/python3.10/site-packages (from gensim) (6.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpITqxI8ugWq"
   },
   "source": [
    "### imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "OiLsmKu-ujrK",
    "ExecuteTime": {
     "end_time": "2023-05-12T10:10:08.849912Z",
     "start_time": "2023-05-12T10:10:08.843997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/uni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import csv\n",
    "import numpy as np\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YruF5M9t3-0"
   },
   "source": [
    "### load dataset into memory\n",
    "return a list of docs and a list of respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YOaqXlBmtssb",
    "ExecuteTime": {
     "end_time": "2023-05-12T09:11:39.833088Z",
     "start_time": "2023-05-12T09:11:39.817925Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data (filename):\n",
    "  content = list()\n",
    "  labels = list()\n",
    "\n",
    "  has_header = True\n",
    "  # detect if file has a header\n",
    "  # with open(filename, 'r') as file:\n",
    "  #   sample = file.read(64)\n",
    "  #   has_header = csv.Sniffer().has_header(sample)\n",
    "\n",
    "  with open(filename, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    # skip first line if file has a header \n",
    "    if has_header:\n",
    "      next(reader)\n",
    "    for c, l in reader:\n",
    "      content.append(c)\n",
    "      labels.append(l)\n",
    "  return content, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsvSHK0Bt99T"
   },
   "source": [
    "### turn a dataset into clean tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N0Ig0SQvuJvd",
    "ExecuteTime": {
     "end_time": "2023-05-12T09:11:40.766056Z",
     "start_time": "2023-05-12T09:11:40.755381Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "  corpus = list()\n",
    "  corp_voc = dict()\n",
    "  stop = nltk.corpus.stopwords.words(\"english\")\n",
    "  # regex tokenizer, find words, numbers and words containing '\n",
    "  tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+(?:'\\w)?\")\n",
    "  for doc in data:\n",
    "    doc = tokenizer.tokenize(doc)\n",
    "    doc_cleaned = dict()\n",
    "    for tok in doc:\n",
    "      # make all words lower case\n",
    "      tok = tok.lower()\n",
    "      # filter out numbers \n",
    "      if not tok.isdigit() and tok not in stop:\n",
    "        # add clean token to document\n",
    "        if tok in doc_cleaned:\n",
    "          doc_cleaned[tok] += 1\n",
    "        else:\n",
    "          doc_cleaned[tok] = 1\n",
    "    for tok in doc_cleaned.keys():\n",
    "    # increase corpus vocabulary\n",
    "        if tok in corp_voc:\n",
    "          corp_voc[tok] += 1\n",
    "        else:\n",
    "          corp_voc[tok] = 1\n",
    "    corpus.append(doc_cleaned)\n",
    "  return corpus, corp_voc\n",
    "\n",
    "# filter all words out of a corpus that are not in a vocabulary\n",
    "def get_filtered_corpus(corpus, vocab):\n",
    "  clean_corpus = list()\n",
    "  for doc in corpus:\n",
    "    clean_doc = dict()\n",
    "    for tok in doc:\n",
    "      if tok in vocab:\n",
    "        clean_doc[tok] = doc[tok]\n",
    "    clean_corpus.append(clean_doc)\n",
    "  return clean_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZInuMNEMuPVI"
   },
   "source": [
    "### preprocess the dataset\n",
    "\n",
    "tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E-XqdPRJuSA_",
    "ExecuteTime": {
     "end_time": "2023-05-12T09:11:41.463457Z",
     "start_time": "2023-05-12T09:11:41.458072Z"
    }
   },
   "outputs": [],
   "source": [
    "# corpus must be a list of dicts of form (token: occurences)\n",
    "# vocab must be a dict of form (token: documents in corpus containing token)\n",
    "def preprocess_tf_idf(corpus, vocab):\n",
    "  processed = np.zeros((len(corpus), len(vocab)))\n",
    "  idf = get_idf(vocab)\n",
    "  token_order = {tok: i for i, tok, in enumerate(sorted(vocab.keys()))}\n",
    "  for n_doc, doc in enumerate(corpus):\n",
    "    tf = get_tf(doc)\n",
    "    for tok in set(doc):\n",
    "      tok_pos = token_order[tok]\n",
    "      processed[n_doc][tok_pos] = tf[tok]*idf[tok]\n",
    "  return processed\n",
    "\n",
    "def get_tf(doc):\n",
    "  tf = dict()\n",
    "  for tok, occ in doc.items():\n",
    "    tf[tok] = occ / len(doc)\n",
    "  return tf\n",
    "\n",
    "def get_idf(corp_voc):\n",
    "  idf = dict()\n",
    "  for tok, docs_containing in corp_voc.items():\n",
    "    idf[tok] = np.log10(len(corp_voc) / docs_containing)\n",
    "  return idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic embeddings\n",
    "pooling word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T10:31:41.188385Z",
     "start_time": "2023-05-12T10:31:41.184379Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_sem_vec(corpus):\n",
    "  processed = list()\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "  total_used = 0\n",
    "  total_available = 0\n",
    "  for n_doc, doc in enumerate(corpus):\n",
    "    vecs = [occ*model[tok] for tok, occ in doc.items() if tok in model.key_to_index]\n",
    "    total_used += len(vecs)\n",
    "    total_available += len(doc.items())\n",
    "    processed.append(np.mean(vecs, axis=0))\n",
    "\n",
    "  return np.array(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "load training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# read data from file\n",
    "raw_data, labels = load_data(\"Train.csv\")\n",
    "full_corpus, full_vocab = clean_data(raw_data)\n",
    "\n",
    "# select part of vocabulary\n",
    "frequencies = sorted(full_vocab.items(), key=lambda x : x[1], reverse=True)\n",
    "# number of most common non-stop words that we consider\n",
    "VOCAB_SIZE = 5000\n",
    "# number of most frequent words to be disregarded, but this is now irrelevant due to the removal of stop words\n",
    "HIGHER_CUTOFF = 0\n",
    "vocab = {x[0] : x[1] for x in frequencies[HIGHER_CUTOFF:HIGHER_CUTOFF+VOCAB_SIZE]}\n",
    "\n",
    "corpus = get_filtered_corpus(full_corpus, vocab.keys())\n",
    "# process labels\n",
    "taining_labels = np.array([0 if int(label) == 0 else 1 for label in labels]) # keras.utils.to_categorical(labels, num_classes=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T10:23:07.429322Z",
     "start_time": "2023-05-12T10:22:57.501692Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load validation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "v_raw, v_labels = load_data(\"Valid.csv\")\n",
    "full_valid_corpus, _ = clean_data(v_raw)\n",
    "valid_corpus = get_filtered_corpus(full_valid_corpus, vocab)\n",
    "valid_labels = np.array([0 if int(label) == 0 else 1 for label in v_labels]) # keras.utils.to_categorical(v_labels, num_classes=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:32:39.724217Z",
     "start_time": "2023-05-12T09:32:38.489864Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "t_raw, t_labels = load_data(\"Test.csv\")\n",
    "full_test_corpus, _ = clean_data(t_raw)\n",
    "test_corpus = get_filtered_corpus(full_test_corpus, vocab)\n",
    "test_labels = np.array([0 if int(label) == 0 else 1 for label in t_labels]) # keras.utils.to_categorical(t_labels, num_classes=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:32:40.964791Z",
     "start_time": "2023-05-12T09:32:39.725046Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "define and preprocess training, testing and validation data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# get tf-idf representation of data\n",
    "tfidf_data = preprocess_tf_idf(corpus, vocab)\n",
    "test_data = preprocess_tf_idf(test_corpus, vocab)\n",
    "valid_data = preprocess_tf_idf(valid_corpus, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:32:42.575018Z",
     "start_time": "2023-05-12T09:32:41.009553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T10:32:23.728559Z",
     "start_time": "2023-05-12T10:31:45.019076Z"
    }
   },
   "outputs": [],
   "source": [
    "# get semantic embeddings of data\n",
    "w2v_train_data = preprocess_sem_vec(corpus)\n",
    "w2v_valid_data = preprocess_sem_vec(valid_corpus)\n",
    "w2v_test_data = preprocess_sem_vec(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### classify a review as negative or positive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def predict_sentiment(model, doc):\n",
    "  return model.predict(doc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:49:40.053928Z",
     "start_time": "2023-05-12T09:49:40.047710Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### define the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "def define_tf_idf_model(dropout=0.2, l1=1e-5, l2=1e-4):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(layers.Dropout(dropout))\n",
    "  model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "  model.add(layers.Dropout(dropout))\n",
    "  model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T10:49:00.099311Z",
     "start_time": "2023-05-12T10:49:00.091847Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the model\n",
    "\n",
    "Setting constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "TF_LEARNING_RATE = 4e-4\n",
    "TF_BATCH_SIZE = 512\n",
    "TF_EPOCHS = 100\n",
    "\n",
    "TF_DROPOUT = 0.25\n",
    "TF_L1 = 5e-6\n",
    "TF_L2 = 5e-5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T10:51:34.093821Z",
     "start_time": "2023-05-12T10:51:34.089872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6147 - accuracy: 0.8171 - val_loss: 0.6086 - val_accuracy: 0.8412\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6059 - accuracy: 0.8238 - val_loss: 0.6006 - val_accuracy: 0.8438\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5986 - accuracy: 0.8285 - val_loss: 0.5931 - val_accuracy: 0.8478\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5910 - accuracy: 0.8319 - val_loss: 0.5857 - val_accuracy: 0.8494\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5855 - accuracy: 0.8333 - val_loss: 0.5793 - val_accuracy: 0.8506\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5795 - accuracy: 0.8361 - val_loss: 0.5731 - val_accuracy: 0.8542\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.8376 - val_loss: 0.5675 - val_accuracy: 0.8538\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5677 - accuracy: 0.8427 - val_loss: 0.5622 - val_accuracy: 0.8586\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5625 - accuracy: 0.8414 - val_loss: 0.5568 - val_accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5581 - accuracy: 0.8453 - val_loss: 0.5520 - val_accuracy: 0.8582\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5521 - accuracy: 0.8487 - val_loss: 0.5475 - val_accuracy: 0.8574\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5491 - accuracy: 0.8484 - val_loss: 0.5430 - val_accuracy: 0.8616\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5447 - accuracy: 0.8489 - val_loss: 0.5392 - val_accuracy: 0.8604\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5406 - accuracy: 0.8523 - val_loss: 0.5353 - val_accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5369 - accuracy: 0.8515 - val_loss: 0.5316 - val_accuracy: 0.8604\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5341 - accuracy: 0.8526 - val_loss: 0.5281 - val_accuracy: 0.8636\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5323 - accuracy: 0.8510 - val_loss: 0.5248 - val_accuracy: 0.8648\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.8547 - val_loss: 0.5217 - val_accuracy: 0.8660\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5237 - accuracy: 0.8564 - val_loss: 0.5185 - val_accuracy: 0.8644\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5208 - accuracy: 0.8567 - val_loss: 0.5156 - val_accuracy: 0.8662\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5191 - accuracy: 0.8567 - val_loss: 0.5128 - val_accuracy: 0.8648\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5158 - accuracy: 0.8584 - val_loss: 0.5102 - val_accuracy: 0.8682\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5139 - accuracy: 0.8571 - val_loss: 0.5075 - val_accuracy: 0.8676\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5117 - accuracy: 0.8594 - val_loss: 0.5049 - val_accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5083 - accuracy: 0.8596 - val_loss: 0.5025 - val_accuracy: 0.8688\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5058 - accuracy: 0.8622 - val_loss: 0.5001 - val_accuracy: 0.8684\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5022 - accuracy: 0.8624 - val_loss: 0.4977 - val_accuracy: 0.8696\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5011 - accuracy: 0.8613 - val_loss: 0.4955 - val_accuracy: 0.8704\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4990 - accuracy: 0.8613 - val_loss: 0.4939 - val_accuracy: 0.8700\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4968 - accuracy: 0.8625 - val_loss: 0.4915 - val_accuracy: 0.8702\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4942 - accuracy: 0.8644 - val_loss: 0.4893 - val_accuracy: 0.8692\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4923 - accuracy: 0.8653 - val_loss: 0.4873 - val_accuracy: 0.8704\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4907 - accuracy: 0.8665 - val_loss: 0.4853 - val_accuracy: 0.8706\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4890 - accuracy: 0.8634 - val_loss: 0.4834 - val_accuracy: 0.8710\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4876 - accuracy: 0.8658 - val_loss: 0.4816 - val_accuracy: 0.8698\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4866 - accuracy: 0.8655 - val_loss: 0.4801 - val_accuracy: 0.8718\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4831 - accuracy: 0.8657 - val_loss: 0.4784 - val_accuracy: 0.8718\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4830 - accuracy: 0.8662 - val_loss: 0.4764 - val_accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4801 - accuracy: 0.8664 - val_loss: 0.4753 - val_accuracy: 0.8744\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.8684 - val_loss: 0.4732 - val_accuracy: 0.8728\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4779 - accuracy: 0.8691 - val_loss: 0.4718 - val_accuracy: 0.8726\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4763 - accuracy: 0.8674 - val_loss: 0.4705 - val_accuracy: 0.8716\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4743 - accuracy: 0.8660 - val_loss: 0.4686 - val_accuracy: 0.8740\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4717 - accuracy: 0.8688 - val_loss: 0.4671 - val_accuracy: 0.8736\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4707 - accuracy: 0.8709 - val_loss: 0.4658 - val_accuracy: 0.8744\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4688 - accuracy: 0.8698 - val_loss: 0.4645 - val_accuracy: 0.8730\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4668 - accuracy: 0.8701 - val_loss: 0.4629 - val_accuracy: 0.8734\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4655 - accuracy: 0.8727 - val_loss: 0.4615 - val_accuracy: 0.8738\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4652 - accuracy: 0.8712 - val_loss: 0.4601 - val_accuracy: 0.8746\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.8718 - val_loss: 0.4588 - val_accuracy: 0.8748\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4626 - accuracy: 0.8709 - val_loss: 0.4578 - val_accuracy: 0.8746\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4627 - accuracy: 0.8719 - val_loss: 0.4566 - val_accuracy: 0.8754\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4601 - accuracy: 0.8723 - val_loss: 0.4555 - val_accuracy: 0.8768\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4593 - accuracy: 0.8733 - val_loss: 0.4545 - val_accuracy: 0.8758\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4565 - accuracy: 0.8742 - val_loss: 0.4533 - val_accuracy: 0.8752\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4564 - accuracy: 0.8738 - val_loss: 0.4521 - val_accuracy: 0.8750\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4548 - accuracy: 0.8729 - val_loss: 0.4510 - val_accuracy: 0.8748\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4536 - accuracy: 0.8763 - val_loss: 0.4501 - val_accuracy: 0.8746\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4528 - accuracy: 0.8751 - val_loss: 0.4490 - val_accuracy: 0.8738\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4526 - accuracy: 0.8737 - val_loss: 0.4477 - val_accuracy: 0.8766\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4515 - accuracy: 0.8746 - val_loss: 0.4472 - val_accuracy: 0.8754\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4504 - accuracy: 0.8749 - val_loss: 0.4457 - val_accuracy: 0.8778\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4486 - accuracy: 0.8744 - val_loss: 0.4450 - val_accuracy: 0.8772\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4482 - accuracy: 0.8753 - val_loss: 0.4439 - val_accuracy: 0.8784\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4477 - accuracy: 0.8755 - val_loss: 0.4430 - val_accuracy: 0.8774\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4460 - accuracy: 0.8765 - val_loss: 0.4425 - val_accuracy: 0.8796\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4441 - accuracy: 0.8767 - val_loss: 0.4414 - val_accuracy: 0.8782\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4432 - accuracy: 0.8776 - val_loss: 0.4407 - val_accuracy: 0.8796\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4431 - accuracy: 0.8766 - val_loss: 0.4398 - val_accuracy: 0.8798\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4421 - accuracy: 0.8783 - val_loss: 0.4389 - val_accuracy: 0.8800\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4412 - accuracy: 0.8773 - val_loss: 0.4390 - val_accuracy: 0.8774\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4390 - accuracy: 0.8786 - val_loss: 0.4372 - val_accuracy: 0.8802\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4376 - accuracy: 0.8800 - val_loss: 0.4372 - val_accuracy: 0.8776\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8780 - val_loss: 0.4356 - val_accuracy: 0.8802\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8765 - val_loss: 0.4350 - val_accuracy: 0.8800\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4376 - accuracy: 0.8772 - val_loss: 0.4344 - val_accuracy: 0.8796\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4346 - accuracy: 0.8795 - val_loss: 0.4338 - val_accuracy: 0.8808\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.8772 - val_loss: 0.4333 - val_accuracy: 0.8780\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4339 - accuracy: 0.8789 - val_loss: 0.4324 - val_accuracy: 0.8816\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8787 - val_loss: 0.4321 - val_accuracy: 0.8806\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4312 - accuracy: 0.8805 - val_loss: 0.4313 - val_accuracy: 0.8822\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4321 - accuracy: 0.8803 - val_loss: 0.4304 - val_accuracy: 0.8816\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4320 - accuracy: 0.8798 - val_loss: 0.4300 - val_accuracy: 0.8814\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4304 - accuracy: 0.8802 - val_loss: 0.4303 - val_accuracy: 0.8786\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4304 - accuracy: 0.8806 - val_loss: 0.4289 - val_accuracy: 0.8798\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4281 - accuracy: 0.8819 - val_loss: 0.4278 - val_accuracy: 0.8818\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4284 - accuracy: 0.8817 - val_loss: 0.4276 - val_accuracy: 0.8830\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4282 - accuracy: 0.8792 - val_loss: 0.4268 - val_accuracy: 0.8820\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4287 - accuracy: 0.8793 - val_loss: 0.4267 - val_accuracy: 0.8812\n",
      "begin evaluation\n",
      "157/157 [==============================] - 0s 607us/step - loss: 0.4247 - accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.42469364404678345, 0.8913999795913696]"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 0.7085 - accuracy: 0.6635 - val_loss: 0.6948 - val_accuracy: 0.7794\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6907 - accuracy: 0.6927 - val_loss: 0.6878 - val_accuracy: 0.7812\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6855 - accuracy: 0.7419 - val_loss: 0.6828 - val_accuracy: 0.7846\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6801 - accuracy: 0.7570 - val_loss: 0.6767 - val_accuracy: 0.7612\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6737 - accuracy: 0.7636 - val_loss: 0.6693 - val_accuracy: 0.7914\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6655 - accuracy: 0.7753 - val_loss: 0.6609 - val_accuracy: 0.8048\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6570 - accuracy: 0.7829 - val_loss: 0.6518 - val_accuracy: 0.8122\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6483 - accuracy: 0.7921 - val_loss: 0.6424 - val_accuracy: 0.8212\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6389 - accuracy: 0.8015 - val_loss: 0.6330 - val_accuracy: 0.8240\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6296 - accuracy: 0.8084 - val_loss: 0.6236 - val_accuracy: 0.8318\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6206 - accuracy: 0.8123 - val_loss: 0.6146 - val_accuracy: 0.8386\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6120 - accuracy: 0.8195 - val_loss: 0.6059 - val_accuracy: 0.8412\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6037 - accuracy: 0.8238 - val_loss: 0.5978 - val_accuracy: 0.8416\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5958 - accuracy: 0.8275 - val_loss: 0.5899 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5888 - accuracy: 0.8284 - val_loss: 0.5827 - val_accuracy: 0.8512\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5815 - accuracy: 0.8368 - val_loss: 0.5759 - val_accuracy: 0.8546\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5755 - accuracy: 0.8372 - val_loss: 0.5696 - val_accuracy: 0.8568\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5703 - accuracy: 0.8401 - val_loss: 0.5638 - val_accuracy: 0.8558\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5649 - accuracy: 0.8439 - val_loss: 0.5582 - val_accuracy: 0.8578\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5601 - accuracy: 0.8426 - val_loss: 0.5532 - val_accuracy: 0.8594\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5554 - accuracy: 0.8440 - val_loss: 0.5485 - val_accuracy: 0.8608\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5499 - accuracy: 0.8479 - val_loss: 0.5440 - val_accuracy: 0.8612\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5454 - accuracy: 0.8503 - val_loss: 0.5396 - val_accuracy: 0.8618\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5430 - accuracy: 0.8489 - val_loss: 0.5359 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5378 - accuracy: 0.8515 - val_loss: 0.5324 - val_accuracy: 0.8640\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5344 - accuracy: 0.8528 - val_loss: 0.5280 - val_accuracy: 0.8634\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5304 - accuracy: 0.8536 - val_loss: 0.5247 - val_accuracy: 0.8640\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5276 - accuracy: 0.8536 - val_loss: 0.5214 - val_accuracy: 0.8652\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5237 - accuracy: 0.8551 - val_loss: 0.5182 - val_accuracy: 0.8664\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5218 - accuracy: 0.8563 - val_loss: 0.5153 - val_accuracy: 0.8642\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5194 - accuracy: 0.8566 - val_loss: 0.5125 - val_accuracy: 0.8666\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5151 - accuracy: 0.8600 - val_loss: 0.5095 - val_accuracy: 0.8668\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5119 - accuracy: 0.8620 - val_loss: 0.5069 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.5104 - accuracy: 0.8587 - val_loss: 0.5046 - val_accuracy: 0.8700\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5081 - accuracy: 0.8608 - val_loss: 0.5020 - val_accuracy: 0.8704\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5065 - accuracy: 0.8598 - val_loss: 0.4995 - val_accuracy: 0.8678\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5037 - accuracy: 0.8609 - val_loss: 0.4971 - val_accuracy: 0.8694\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.5024 - accuracy: 0.8615 - val_loss: 0.4948 - val_accuracy: 0.8694\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4986 - accuracy: 0.8632 - val_loss: 0.4926 - val_accuracy: 0.8716\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4962 - accuracy: 0.8622 - val_loss: 0.4905 - val_accuracy: 0.8690\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4942 - accuracy: 0.8636 - val_loss: 0.4884 - val_accuracy: 0.8712\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4910 - accuracy: 0.8665 - val_loss: 0.4872 - val_accuracy: 0.8686\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4899 - accuracy: 0.8656 - val_loss: 0.4846 - val_accuracy: 0.8694\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4876 - accuracy: 0.8667 - val_loss: 0.4826 - val_accuracy: 0.8726\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4863 - accuracy: 0.8651 - val_loss: 0.4805 - val_accuracy: 0.8718\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4841 - accuracy: 0.8647 - val_loss: 0.4788 - val_accuracy: 0.8710\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4835 - accuracy: 0.8672 - val_loss: 0.4773 - val_accuracy: 0.8738\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4802 - accuracy: 0.8682 - val_loss: 0.4758 - val_accuracy: 0.8720\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4786 - accuracy: 0.8695 - val_loss: 0.4741 - val_accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4772 - accuracy: 0.8688 - val_loss: 0.4724 - val_accuracy: 0.8740\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4769 - accuracy: 0.8683 - val_loss: 0.4711 - val_accuracy: 0.8734\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.8716 - val_loss: 0.4695 - val_accuracy: 0.8712\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4733 - accuracy: 0.8688 - val_loss: 0.4679 - val_accuracy: 0.8732\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4713 - accuracy: 0.8696 - val_loss: 0.4672 - val_accuracy: 0.8736\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4708 - accuracy: 0.8724 - val_loss: 0.4651 - val_accuracy: 0.8728\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4675 - accuracy: 0.8713 - val_loss: 0.4639 - val_accuracy: 0.8774\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4667 - accuracy: 0.8707 - val_loss: 0.4624 - val_accuracy: 0.8746\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4632 - accuracy: 0.8741 - val_loss: 0.4608 - val_accuracy: 0.8734\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4645 - accuracy: 0.8709 - val_loss: 0.4598 - val_accuracy: 0.8760\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4631 - accuracy: 0.8725 - val_loss: 0.4582 - val_accuracy: 0.8758\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4621 - accuracy: 0.8721 - val_loss: 0.4569 - val_accuracy: 0.8756\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4600 - accuracy: 0.8738 - val_loss: 0.4557 - val_accuracy: 0.8766\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4584 - accuracy: 0.8729 - val_loss: 0.4543 - val_accuracy: 0.8762\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4579 - accuracy: 0.8726 - val_loss: 0.4534 - val_accuracy: 0.8756\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4567 - accuracy: 0.8734 - val_loss: 0.4529 - val_accuracy: 0.8758\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4545 - accuracy: 0.8742 - val_loss: 0.4520 - val_accuracy: 0.8756\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4554 - accuracy: 0.8738 - val_loss: 0.4504 - val_accuracy: 0.8770\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4531 - accuracy: 0.8742 - val_loss: 0.4490 - val_accuracy: 0.8762\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4515 - accuracy: 0.8752 - val_loss: 0.4485 - val_accuracy: 0.8762\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4506 - accuracy: 0.8752 - val_loss: 0.4472 - val_accuracy: 0.8768\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4493 - accuracy: 0.8750 - val_loss: 0.4463 - val_accuracy: 0.8790\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4485 - accuracy: 0.8775 - val_loss: 0.4451 - val_accuracy: 0.8780\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4476 - accuracy: 0.8769 - val_loss: 0.4445 - val_accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4462 - accuracy: 0.8766 - val_loss: 0.4435 - val_accuracy: 0.8784\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4456 - accuracy: 0.8763 - val_loss: 0.4424 - val_accuracy: 0.8774\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4438 - accuracy: 0.8798 - val_loss: 0.4414 - val_accuracy: 0.8770\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4424 - accuracy: 0.8766 - val_loss: 0.4417 - val_accuracy: 0.8768\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4438 - accuracy: 0.8769 - val_loss: 0.4401 - val_accuracy: 0.8784\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4422 - accuracy: 0.8773 - val_loss: 0.4391 - val_accuracy: 0.8786\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4412 - accuracy: 0.8776 - val_loss: 0.4382 - val_accuracy: 0.8784\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4388 - accuracy: 0.8790 - val_loss: 0.4376 - val_accuracy: 0.8774\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4381 - accuracy: 0.8812 - val_loss: 0.4366 - val_accuracy: 0.8802\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4386 - accuracy: 0.8783 - val_loss: 0.4367 - val_accuracy: 0.8808\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4374 - accuracy: 0.8792 - val_loss: 0.4356 - val_accuracy: 0.8796\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4366 - accuracy: 0.8781 - val_loss: 0.4353 - val_accuracy: 0.8782\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4365 - accuracy: 0.8787 - val_loss: 0.4344 - val_accuracy: 0.8794\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4355 - accuracy: 0.8787 - val_loss: 0.4337 - val_accuracy: 0.8790\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4351 - accuracy: 0.8783 - val_loss: 0.4329 - val_accuracy: 0.8788\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4336 - accuracy: 0.8799 - val_loss: 0.4323 - val_accuracy: 0.8794\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4350 - accuracy: 0.8776 - val_loss: 0.4316 - val_accuracy: 0.8804\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4329 - accuracy: 0.8800 - val_loss: 0.4314 - val_accuracy: 0.8780\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4324 - accuracy: 0.8802 - val_loss: 0.4301 - val_accuracy: 0.8812\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4334 - accuracy: 0.8795 - val_loss: 0.4303 - val_accuracy: 0.8808\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4309 - accuracy: 0.8805 - val_loss: 0.4293 - val_accuracy: 0.8810\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4290 - accuracy: 0.8823 - val_loss: 0.4286 - val_accuracy: 0.8810\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8808 - val_loss: 0.4281 - val_accuracy: 0.8818\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4297 - accuracy: 0.8813 - val_loss: 0.4276 - val_accuracy: 0.8812\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4265 - accuracy: 0.8824 - val_loss: 0.4280 - val_accuracy: 0.8800\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4282 - accuracy: 0.8812 - val_loss: 0.4265 - val_accuracy: 0.8816\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.4277 - accuracy: 0.8808 - val_loss: 0.4262 - val_accuracy: 0.8800\n",
      "begin evaluation\n",
      "157/157 [==============================] - 0s 625us/step - loss: 0.4240 - accuracy: 0.8902\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4239771068096161, 0.8902000188827515]"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "tfidf_model = define_tf_idf_model(dropout=TF_DROPOUT, l1=TF_L1, l2=TF_L2)\n",
    "tfidf_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=TF_LEARNING_RATE),\n",
    "    metrics=['accuracy'])\n",
    "# train model\n",
    "print(\"begin training\")\n",
    "tfidf_model.fit(\n",
    "    tfidf_data,\n",
    "    taining_labels,\n",
    "    validation_data=(valid_data, valid_labels),\n",
    "    epochs=TF_EPOCHS,\n",
    "    batch_size=TF_BATCH_SIZE)\n",
    "print(\"begin evaluation\")\n",
    "tfidf_model.evaluate(test_data, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train a model on word2vec embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def define_word2vec_model(dropout=0.4, l1=1e-5, l2=1e-4):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(layers.Dropout(dropout))\n",
    "  model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "  model.add(layers.Dropout(dropout))\n",
    "  model.add(layers.Dense(128, activation='relu', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "  model.add(layers.Dropout(dropout))\n",
    "  model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer=regularizers.L1L2(l1=l1, l2=l2)))\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T10:54:20.705002Z",
     "start_time": "2023-05-12T10:54:20.700670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "W2V_LEARNING_RATE = 2e-4\n",
    "W2V_BATCH_SIZE = 512\n",
    "W2V_EPOCHS = 100\n",
    "\n",
    "W2V_DROPOUT = 0.1\n",
    "W2V_L1 = 2e-5\n",
    "W2V_L2 = 1e-4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T10:54:51.736661Z",
     "start_time": "2023-05-12T10:54:51.733443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T10:55:28.710589Z",
     "start_time": "2023-05-12T10:54:51.891032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.8013 - accuracy: 0.7027 - val_loss: 0.6961 - val_accuracy: 0.7980\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.7897 - val_loss: 0.5550 - val_accuracy: 0.8172\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.8091 - val_loss: 0.5098 - val_accuracy: 0.8322\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8188 - val_loss: 0.4874 - val_accuracy: 0.8432\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.8240 - val_loss: 0.4739 - val_accuracy: 0.8462\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.8266 - val_loss: 0.4643 - val_accuracy: 0.8472\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.8269 - val_loss: 0.4571 - val_accuracy: 0.8494\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.8287 - val_loss: 0.4507 - val_accuracy: 0.8536\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.8284 - val_loss: 0.4526 - val_accuracy: 0.8454\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.8299 - val_loss: 0.4443 - val_accuracy: 0.8514\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.8295 - val_loss: 0.4393 - val_accuracy: 0.8552\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.8311 - val_loss: 0.4368 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8307 - val_loss: 0.4371 - val_accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8305 - val_loss: 0.4320 - val_accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8316 - val_loss: 0.4297 - val_accuracy: 0.8538\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8316 - val_loss: 0.4278 - val_accuracy: 0.8530\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.8299 - val_loss: 0.4319 - val_accuracy: 0.8474\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8324 - val_loss: 0.4246 - val_accuracy: 0.8522\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.8326 - val_loss: 0.4241 - val_accuracy: 0.8538\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.8311 - val_loss: 0.4214 - val_accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8329 - val_loss: 0.4190 - val_accuracy: 0.8540\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8322 - val_loss: 0.4175 - val_accuracy: 0.8544\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8327 - val_loss: 0.4170 - val_accuracy: 0.8536\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8352 - val_loss: 0.4152 - val_accuracy: 0.8554\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.8334 - val_loss: 0.4142 - val_accuracy: 0.8554\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.8341 - val_loss: 0.4178 - val_accuracy: 0.8492\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8321 - val_loss: 0.4123 - val_accuracy: 0.8544\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8336 - val_loss: 0.4099 - val_accuracy: 0.8560\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8352 - val_loss: 0.4120 - val_accuracy: 0.8544\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8345 - val_loss: 0.4072 - val_accuracy: 0.8582\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8329 - val_loss: 0.4075 - val_accuracy: 0.8558\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8338 - val_loss: 0.4066 - val_accuracy: 0.8572\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8346 - val_loss: 0.4038 - val_accuracy: 0.8568\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8350 - val_loss: 0.4032 - val_accuracy: 0.8584\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8348 - val_loss: 0.4071 - val_accuracy: 0.8514\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8325 - val_loss: 0.4019 - val_accuracy: 0.8594\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8351 - val_loss: 0.4009 - val_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8349 - val_loss: 0.4002 - val_accuracy: 0.8576\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8346 - val_loss: 0.3985 - val_accuracy: 0.8554\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8339 - val_loss: 0.4011 - val_accuracy: 0.8528\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8359 - val_loss: 0.3971 - val_accuracy: 0.8592\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8357 - val_loss: 0.3994 - val_accuracy: 0.8546\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8376 - val_loss: 0.3956 - val_accuracy: 0.8576\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8340 - val_loss: 0.3956 - val_accuracy: 0.8590\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8356 - val_loss: 0.3949 - val_accuracy: 0.8576\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8371 - val_loss: 0.3929 - val_accuracy: 0.8570\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8343 - val_loss: 0.3929 - val_accuracy: 0.8582\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8359 - val_loss: 0.3923 - val_accuracy: 0.8586\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8349 - val_loss: 0.3918 - val_accuracy: 0.8590\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8365 - val_loss: 0.3930 - val_accuracy: 0.8560\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8353 - val_loss: 0.3917 - val_accuracy: 0.8582\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8372 - val_loss: 0.3895 - val_accuracy: 0.8588\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8342 - val_loss: 0.3893 - val_accuracy: 0.8586\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.8382 - val_loss: 0.3883 - val_accuracy: 0.8596\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8382 - val_loss: 0.3876 - val_accuracy: 0.8584\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8366 - val_loss: 0.3873 - val_accuracy: 0.8574\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8359 - val_loss: 0.3866 - val_accuracy: 0.8600\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8357 - val_loss: 0.3866 - val_accuracy: 0.8590\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8366 - val_loss: 0.3860 - val_accuracy: 0.8590\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8378 - val_loss: 0.3866 - val_accuracy: 0.8578\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8369 - val_loss: 0.3840 - val_accuracy: 0.8596\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8362 - val_loss: 0.3853 - val_accuracy: 0.8592\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8366 - val_loss: 0.3842 - val_accuracy: 0.8584\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8381 - val_loss: 0.3842 - val_accuracy: 0.8578\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8365 - val_loss: 0.3828 - val_accuracy: 0.8598\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8386 - val_loss: 0.3872 - val_accuracy: 0.8560\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8370 - val_loss: 0.3854 - val_accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8358 - val_loss: 0.3813 - val_accuracy: 0.8590\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8369 - val_loss: 0.3813 - val_accuracy: 0.8610\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8373 - val_loss: 0.3821 - val_accuracy: 0.8580\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8368 - val_loss: 0.3802 - val_accuracy: 0.8590\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8374 - val_loss: 0.3808 - val_accuracy: 0.8594\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8394 - val_loss: 0.3805 - val_accuracy: 0.8588\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8383 - val_loss: 0.3804 - val_accuracy: 0.8574\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8393 - val_loss: 0.3787 - val_accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8377 - val_loss: 0.3785 - val_accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8409 - val_loss: 0.3780 - val_accuracy: 0.8608\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8399 - val_loss: 0.3782 - val_accuracy: 0.8592\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8405 - val_loss: 0.3764 - val_accuracy: 0.8622\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8400 - val_loss: 0.3750 - val_accuracy: 0.8596\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8400 - val_loss: 0.3789 - val_accuracy: 0.8586\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8426 - val_loss: 0.3770 - val_accuracy: 0.8612\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8410 - val_loss: 0.3749 - val_accuracy: 0.8614\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8382 - val_loss: 0.3762 - val_accuracy: 0.8586\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8394 - val_loss: 0.3768 - val_accuracy: 0.8598\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8401 - val_loss: 0.3748 - val_accuracy: 0.8592\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8403 - val_loss: 0.3740 - val_accuracy: 0.8590\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8405 - val_loss: 0.3735 - val_accuracy: 0.8588\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8403 - val_loss: 0.3762 - val_accuracy: 0.8594\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8406 - val_loss: 0.3730 - val_accuracy: 0.8600\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8409 - val_loss: 0.3765 - val_accuracy: 0.8544\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8403 - val_loss: 0.3727 - val_accuracy: 0.8602\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8389 - val_loss: 0.3713 - val_accuracy: 0.8614\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8411 - val_loss: 0.3711 - val_accuracy: 0.8600\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8411 - val_loss: 0.3705 - val_accuracy: 0.8600\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8423 - val_loss: 0.3740 - val_accuracy: 0.8594\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8423 - val_loss: 0.3698 - val_accuracy: 0.8612\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8412 - val_loss: 0.3703 - val_accuracy: 0.8616\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8414 - val_loss: 0.3711 - val_accuracy: 0.8624\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8407 - val_loss: 0.3695 - val_accuracy: 0.8604\n",
      "begin evaluation\n",
      "157/157 [==============================] - 0s 580us/step - loss: 0.3807 - accuracy: 0.8556\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3807304799556732, 0.8555999994277954]"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "w2v_model = define_word2vec_model(dropout=W2V_DROPOUT, l1=W2V_L1, l2=W2V_L2)\n",
    "w2v_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=W2V_LEARNING_RATE),\n",
    "    metrics=['accuracy'])\n",
    "# train model\n",
    "print(\"begin training\")\n",
    "w2v_model.fit(\n",
    "    w2v_train_data,\n",
    "    taining_labels,\n",
    "    validation_data=(w2v_valid_data, valid_labels),\n",
    "    epochs=W2V_EPOCHS,\n",
    "    batch_size=W2V_BATCH_SIZE)\n",
    "print(\"begin evaluation\")\n",
    "w2v_model.evaluate(w2v_test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPun9gmYIf9t/BZSermdCJL",
   "include_colab_link": true,
   "mount_file_id": "1DkZU-n7fDBOIj7zec3xzfRXH0jZgeOaV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
